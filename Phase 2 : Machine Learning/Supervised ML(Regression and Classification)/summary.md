# âœ…Supervised Learning â€“ Core ML Algorithms

In this segment, I focused solely on **Supervised Learning**, where the model learns from labeled data to make predictions.  
I explored foundational regression and classification models, learned their theory, built them from scratch, and evaluated performance.

---

## ðŸ“˜ What is Supervised Learning?

Supervised learning uses **input-output pairs** (features and labels) to train models that predict:
- **Continuous values** (Regression)
- **Categories** (Classification)

---

## ðŸ“… Daily Breakdown

### ðŸ“Œ **ML Introduction**
- Supervised vs. Unsupervised Learning
- ML workflow: preprocessing â†’ training â†’ evaluation â†’ tuning
- Tools: `scikit-learn`, `numpy`, `pandas`

---

### ðŸ“Œ **Linear Regression**
- Predicting numeric outputs (e.g., house prices)
- Concepts: line of best fit, MSE loss, gradient descent
- Built using `scikit-learn` and from scratch

---

### ðŸ“Œ **Logistic Regression**
- Binary classification (e.g., spam vs. not spam)
- Sigmoid activation, decision boundary
- Evaluation: accuracy, precision, recall, F1 score

---

### ðŸ“Œ **K-Nearest Neighbors (KNN)**
- Instance-based learning
- Predicts based on "closeness" to other data points
- No model training phase (lazy learner)

---

### ðŸ“Œ ** Decision Trees**
- Splits data using conditions (e.g., Gini, Entropy)
- Visual representation of decisions
- Learned how trees can overfit and be pruned

---

### ðŸ“Œ ** Naive Bayes**
- Based on Bayesâ€™ Theorem
- Assumes independent features (Naive assumption)
- Often used in text classification

---

### ðŸ“Œ ** Support Vector Machines (SVM)**
- Finds the best decision boundary (hyperplane)
- Maximizes margin between classes
- Used linear and RBF kernels

---

### ðŸ“Œ **Model Evaluation & Comparison**
- Compared all supervised models
- Used metrics: Accuracy, Precision, Recall, F1, ROC-AUC
- Learned when to use which model

---

### ðŸ“Œ ** Wrap-Up + Real Dataset Application**
- Applied multiple models to a real dataset (e.g., Iris, Titanic, Breast Cancer)
- Performed train/test split, feature scaling, evaluation
- Consolidated understanding before moving to advanced topics

---

## âœ… Outcome

By the end, I could:
- Build, tune, and evaluate classical ML models for supervised learning
- Understand the mathematical intuition behind them
- Apply models to real-world structured datasets with proper evaluation

---
